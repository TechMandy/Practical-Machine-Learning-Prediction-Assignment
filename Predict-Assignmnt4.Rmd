---
title: "Predict-Assignment-4-Practicle Machine learning Project"
Subtitle: "Human Activity Recognition Model"
date: "`r Sys.Date()`"
output: html_document
---

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. 

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.

In this project, the goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).
Data

The training data for this project are available here:
  
  https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here:
  
  https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har.

The data can be downloaded using the below R script.

```{r}
downloadFiles<-function(
  dataURL="", destF="t.csv"
){
  if(!file.exists(destF)){
    download.file(dataURL, destF, method="curl")
  }else{
    message("data already downloaded.")
  }
}
```

### loading training and testing dataset
```{r}
trainURL<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testURL <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
downloadFiles(trainURL, "pml-training.csv")
```

## data already downloaded.
```{r}
downloadFiles(testURL, "pml-test.csv")
```

## data already downloaded.

```{r}
training <- read.csv("C:/Users/Mandeep/Desktop/My studies/Data Science/8-Practical Machine Learning/P-3/submit/pml-training.csv", header = TRUE, sep =",", na.strings= c("NA",""," "))
testing <-read.csv("C:/Users/Mandeep/Desktop/My studies/Data Science/8-Practical Machine Learning/P-3/submit/pml-testing-1.csv", header = TRUE, sep = ",", na.strings= c("NA",""," "))
```

First look of training data
```{r}
dim(training)
```

The outcome is "classe" variable
```{r}
table(training$classe)
```

The train dataset has 160 variables 19622 observations.

### remove missing values, is.na() or ""

```{r}
var <- names(training)[apply(training,2,function(x) table(is.na(x))[1]==19622)]   
train2<- training[,var]
test2 <- testing[,c(var[-length(var)],names(testing)[length(testing)])]
# test dataset no classe variable
```

### discards unuseful predictors

Only considering numeric variable from HAR sensor

```{r}
removeIndex <- grep("timestamp|X|user_name|new_window|num_window",names(train2))
train3 <- train2[,-c(removeIndex, length(train2))]
test3  <- test2[,-c(removeIndex, length(test2))]
```

##Check the near Zero covariates and correlation matrix

removing zero covariates
```{r}
library(caret)
```

## Loading required package: lattice
## Loading required package: ggplot2

```{r}
nzv <- nearZeroVar(train3, saveMetrics=TRUE)
nzv
```

```{r}
nzv[nzv$nzv,]
```

## Remove highly correlated covariates.
```{r, echo=TRUE}
corrM <- cor(train3)
library(corrplot)
corrplot(corrM, method="circle",tl.cex=0.5)
```

plot of chunk checkCorrelation
```{r}
highCorr <- findCorrelation(corrM, cutoff = .75)     # high correlation
train4<-cbind(classe=train2$classe,train3[,-highCorr])    
test4 <- test3[, -highCorr]        # dataframe of test predictors
```

### Split training dataset into training/testing for model evaulation

```{r}
set.seed(1234)
inTrain = createDataPartition(train4$classe, p = 3/4)[[1]]
trainPart = train4[ inTrain,]
testPart =  train4[-inTrain,]
```

## Random Forest algorithm to predict.
```{r}
library(randomForest)
```


```{r}
rfModel <- randomForest(classe ~ .,data = trainPart,importance = TRUE,ntrees = 500)
print(rfModel)
```

```{r, echo=TRUE}
par(mar=c(3,4,4,4))                               
plot(rfModel)
```

plot of chunk randomForest
```{r,echo=TRUE}
varImpPlot(rfModel,cex=.5)  
```

plot of chunk randomForest

## Test sample and cross validation
```{r}
out.test<-predict(rfModel,test4) 
out.test[1:20]
```

### k fold cross validataion, which takes too much computing time
### PCA with threshold 0.80, two misclassified in the first 20.

```{r}
preProc <- preProcess(trainPart[,-1], method="pca", thresh=0.8)
trainPC <- predict(preProc, trainPart[,-1])
#modPC <- train(trainPart$classe~., method="rf", data=trainPC)
modPC <- randomForest(trainPart$classe~., data=trainPC, importance=TRUE, ntree=10)

testPC <- predict(preProc, testPart[,-1])
out.testPC<-predict(modPC, newdata=testPC)
table(out.testPC, testPart$classe)
```

```{r}
testPC <- predict(preProc, test4)
out.testPC<-predict(modPC, newdata=testPC)
```

```{r}
out.testPC[1:20]  # the 1st and 3rd mis-classified
```


```{r}
out.test[1:20]==out.testPC[1:20]
```

### saving the output
```{r}
answers<- as.vector(out.test[1:20])
#answers = rep("A", 20)
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
```

```{r}
pml_write_files(answers)
```
